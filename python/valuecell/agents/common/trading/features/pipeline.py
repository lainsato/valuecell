"""Feature pipeline abstractions for the strategy agent.

This module encapsulates the data-fetch and feature-computation steps used by
strategy runtimes. Introducing a dedicated pipeline object means the decision
coordinator no longer needs direct access to the market data source or feature
computerâ€”everything is orchestrated by the pipeline.

Updated: Added multi-timeframe support for better trend analysis.
"""

from __future__ import annotations

import asyncio
import itertools
from typing import List, Optional, Dict, Any

from loguru import logger

from valuecell.agents.common.trading.models import (
    CandleConfig,
    FeaturesPipelineResult,
    FeatureVector,
    UserRequest,
)

from ..data.interfaces import BaseMarketDataSource
from ..data.market import SimpleMarketDataSource
from .candle import SimpleCandleFeatureComputer
from .interfaces import (
    BaseFeaturesPipeline,
    CandleBasedFeatureComputer,
)
from .market_snapshot import MarketSnapshotFeatureComputer


class DefaultFeaturesPipeline(BaseFeaturesPipeline):
    """Default pipeline using the simple data source and feature computer.
    
    Now supports multi-timeframe analysis for better trend detection.
    """

    # å¤šå‘¨æœŸé…ç½®ï¼šç”¨äºŽè¶‹åŠ¿åˆ†æž
    MULTI_TIMEFRAME_CONFIGS = [
        CandleConfig(interval="1m", lookback=120),   # 2å°æ—¶æ•°æ®ï¼Œå…¥åœºæ—¶æœº
        CandleConfig(interval="15m", lookback=96),   # 24å°æ—¶æ•°æ®ï¼ŒçŸ­æœŸè¶‹åŠ¿
        CandleConfig(interval="1h", lookback=168),   # 7å¤©æ•°æ®ï¼Œä¸­æœŸè¶‹åŠ¿
        CandleConfig(interval="4h", lookback=180),   # 30å¤©æ•°æ®ï¼Œä¸»è¶‹åŠ¿
        CandleConfig(interval="1d", lookback=90),    # 90å¤©æ•°æ®ï¼Œé•¿æœŸæ–¹å‘
    ]

    def __init__(
        self,
        *,
        request: UserRequest,
        market_data_source: BaseMarketDataSource,
        candle_feature_computer: CandleBasedFeatureComputer,
        market_snapshot_computer: MarketSnapshotFeatureComputer,
        candle_configurations: Optional[List[CandleConfig]] = None,
        use_multi_timeframe: bool = True,  # æ–°å¢žï¼šæ˜¯å¦ä½¿ç”¨å¤šå‘¨æœŸ
    ) -> None:
        self._request = request
        self._market_data_source = market_data_source
        self._candle_feature_computer = candle_feature_computer
        self._symbols = list(dict.fromkeys(request.trading_config.symbols))
        self._market_snapshot_computer = market_snapshot_computer
        self._use_multi_timeframe = use_multi_timeframe
        
        # æ ¹æ®é…ç½®é€‰æ‹©ä½¿ç”¨å¤šå‘¨æœŸè¿˜æ˜¯åŽŸæ¥çš„é…ç½®
        if use_multi_timeframe:
            self._candle_configurations = self.MULTI_TIMEFRAME_CONFIGS
            logger.info(f"ðŸ“Š Using multi-timeframe analysis: {[c.interval for c in self._candle_configurations]}")
        else:
            self._candle_configurations = candle_configurations or [
                CandleConfig(interval="1s", lookback=60 * 3),
                CandleConfig(interval="1m", lookback=60 * 4),
            ]

    async def build(self) -> FeaturesPipelineResult:
        """
        Fetch candles and market snapshot, compute feature vectors concurrently,
        and combine results.
        
        With multi-timeframe enabled, fetches data across multiple timeframes
        for comprehensive trend analysis.
        """

        async def _fetch_candles(interval: str, lookback: int) -> List[FeatureVector]:
            """Fetches candles and computes features for a single (interval, lookback) pair."""
            try:
                _candles = await self._market_data_source.get_recent_candles(
                    self._symbols, interval, lookback
                )
                if not _candles:
                    logger.warning(f"âš ï¸ No candles returned for [{interval}]")
                    return []
                return self._candle_feature_computer.compute_features(candles=_candles)
            except Exception as e:
                logger.error(f"âŒ Failed to fetch [{interval}] candles: {e}")
                return []

        async def _fetch_market_features() -> List[FeatureVector]:
            """Fetches market snapshot for all symbols and computes features."""
            try:
                market_snapshot = await self._market_data_source.get_market_snapshot(
                    self._symbols
                )
                market_snapshot = market_snapshot or {}
                return self._market_snapshot_computer.build(
                    market_snapshot, self._request.exchange_config.exchange_id
                )
            except Exception as e:
                logger.error(f"âŒ Failed to fetch market snapshot: {e}")
                return []

        timeframes_str = [c.interval for c in self._candle_configurations]
        logger.info(
            f"ðŸ“Š Starting concurrent data fetching for {len(self._candle_configurations)} "
            f"timeframes {timeframes_str} and market snapshot..."
        )
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [
            _fetch_candles(config.interval, config.lookback)
            for config in self._candle_configurations
        ]
        tasks.append(_fetch_market_features())

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æžœï¼Œè¿‡æ»¤å¼‚å¸¸
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"âŒ Task {i} failed with exception: {result}")
                valid_results.append([])
            else:
                valid_results.append(result)
        
        logger.info("âœ… Concurrent data fetching complete.")

        # æœ€åŽä¸€ä¸ªæ˜¯ market_features
        market_features: List[FeatureVector] = valid_results.pop()

        # å±•å¹³æ‰€æœ‰ candle features
        candle_features: List[FeatureVector] = list(
            itertools.chain.from_iterable(valid_results)
        )

        # æ·»åŠ å¤šå‘¨æœŸç»¼åˆåˆ†æžï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if self._use_multi_timeframe and candle_features:
            multi_tf_summary = self._compute_multi_timeframe_summary(candle_features)
            logger.info(f"ðŸ“ˆ Multi-TF Summary: {multi_tf_summary}")

        candle_features.extend(market_features)

        # æ—¥å¿—ç»Ÿè®¡
        total_features = len(candle_features)
        by_interval = {}
        for f in candle_features:
            interval = getattr(f, 'interval', 'snapshot')
            by_interval[interval] = by_interval.get(interval, 0) + 1
        logger.info(f"ðŸ“Š Total features: {total_features}, by interval: {by_interval}")

        return FeaturesPipelineResult(features=candle_features)

    def _compute_multi_timeframe_summary(
        self, 
        features: List[FeatureVector]
    ) -> Dict[str, Any]:
        """è®¡ç®—å¤šå‘¨æœŸè¶‹åŠ¿æ‘˜è¦
        
        åˆ†æžå„å‘¨æœŸçš„è¶‹åŠ¿æ–¹å‘ï¼Œè¾“å‡ºç»¼åˆä¿¡å·ã€‚
        """
        summary = {
            "timeframes_analyzed": [],
            "trend_alignment": "unknown",
            "signals": {},
        }
        
        # æŒ‰å‘¨æœŸåˆ†ç»„
        by_interval: Dict[str, List[FeatureVector]] = {}
        for f in features:
            interval = getattr(f, 'interval', None)
            if interval:
                if interval not in by_interval:
                    by_interval[interval] = []
                by_interval[interval].append(f)
        
        summary["timeframes_analyzed"] = list(by_interval.keys())
        
        # åˆ†æžè¶‹åŠ¿ä¸€è‡´æ€§
        # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´å¤æ‚çš„é€»è¾‘
        bullish_count = 0
        bearish_count = 0
        
        for interval, interval_features in by_interval.items():
            # ç®€åŒ–ï¼šæ£€æŸ¥è¯¥å‘¨æœŸå†…çš„è¶‹åŠ¿ç‰¹å¾
            for f in interval_features:
                # å‡è®¾ FeatureVector æœ‰ trend å±žæ€§
                trend = getattr(f, 'trend', None)
                if trend == 'bullish':
                    bullish_count += 1
                elif trend == 'bearish':
                    bearish_count += 1
        
        if bullish_count > bearish_count * 2:
            summary["trend_alignment"] = "strong_bullish"
        elif bearish_count > bullish_count * 2:
            summary["trend_alignment"] = "strong_bearish"
        elif bullish_count > bearish_count:
            summary["trend_alignment"] = "bullish"
        elif bearish_count > bullish_count:
            summary["trend_alignment"] = "bearish"
        else:
            summary["trend_alignment"] = "neutral"
        
        return summary

    @classmethod
    def from_request(
        cls, 
        request: UserRequest,
        use_multi_timeframe: bool = True,  # æ–°å¢žå‚æ•°
    ) -> DefaultFeaturesPipeline:
        """Factory creating the default pipeline from a user request.
        
        Args:
            request: User request configuration
            use_multi_timeframe: If True, use multi-timeframe analysis (1m, 15m, 1h, 4h, 1d)
                                If False, use original 1s/1m configuration
        """
        market_data_source = SimpleMarketDataSource(
            exchange_id=request.exchange_config.exchange_id
        )
        candle_feature_computer = SimpleCandleFeatureComputer()
        market_snapshot_computer = MarketSnapshotFeatureComputer()
        return cls(
            request=request,
            market_data_source=market_data_source,
            candle_feature_computer=candle_feature_computer,
            market_snapshot_computer=market_snapshot_computer,
            use_multi_timeframe=use_multi_timeframe,
        )